{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5574, 2)\n",
      "  label                                            message\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "['label', 'message']\n",
      "      message                                                               \n",
      "        count unique                                                top freq\n",
      "label                                                                       \n",
      "ham      4827   4518                             Sorry, I'll call later   30\n",
      "spam      747    653  Please call our customer service representativ...    4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina..."
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "dataset=[line.rstrip() for line in open ('C:\\\\Users\\\\ggovinda\\\\Downloads\\\\dataset.csv')]\n",
    "dataset = pd.read_csv(\"C:\\\\Users\\\\ggovinda\\\\Downloads\\\\dataset.csv\",sep='\\t',quoting=csv.QUOTE_NONE, names=['label','message'])\n",
    "\n",
    "print(dataset.shape)\n",
    "print(dataset.head(3))\n",
    "\n",
    "data_col=list(dataset.columns)\n",
    "print(data_col)\n",
    "\n",
    "print(dataset.groupby('label').describe())\n",
    "dataset.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        ham\n",
      "1        ham\n",
      "2       spam\n",
      "3        ham\n",
      "4        ham\n",
      "5       spam\n",
      "6        ham\n",
      "7        ham\n",
      "8       spam\n",
      "9       spam\n",
      "10       ham\n",
      "11      spam\n",
      "12      spam\n",
      "13       ham\n",
      "14       ham\n",
      "15      spam\n",
      "16       ham\n",
      "17       ham\n",
      "18       ham\n",
      "19      spam\n",
      "20       ham\n",
      "21       ham\n",
      "22       ham\n",
      "23       ham\n",
      "24       ham\n",
      "25       ham\n",
      "26       ham\n",
      "27       ham\n",
      "28       ham\n",
      "29       ham\n",
      "        ... \n",
      "5544     ham\n",
      "5545     ham\n",
      "5546     ham\n",
      "5547     ham\n",
      "5548     ham\n",
      "5549    spam\n",
      "5550     ham\n",
      "5551     ham\n",
      "5552     ham\n",
      "5553     ham\n",
      "5554     ham\n",
      "5555     ham\n",
      "5556     ham\n",
      "5557     ham\n",
      "5558     ham\n",
      "5559     ham\n",
      "5560     ham\n",
      "5561     ham\n",
      "5562     ham\n",
      "5563     ham\n",
      "5564     ham\n",
      "5565     ham\n",
      "5566     ham\n",
      "5567     ham\n",
      "5568    spam\n",
      "5569    spam\n",
      "5570     ham\n",
      "5571     ham\n",
      "5572     ham\n",
      "5573     ham\n",
      "Name: label, Length: 5574, dtype: object\n"
     ]
    }
   ],
   "source": [
    "dataset_target = dataset[\"label\"]\n",
    "print(dataset_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def split_token(message):\n",
    "    message = message.lower()\n",
    "   # message = unicode(message,'utf8')\n",
    "    #message = message.encode('utf-8')\n",
    "    word_token=word_tokenize(message)\n",
    "    return word_token\n",
    "\n",
    "dataset[\"token_word\"]=dataset.apply(lambda row:split_token(row['message']), axis=1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_word:  0       [go, until, jurong, point, ,, crazy.., availab...\n",
      "1                [ok, lar, ..., joking, wif, u, oni, ...]\n",
      "2       [free, entry, in, 2, a, wkly, comp, to, win, f...\n",
      "3       [u, dun, say, so, early, hor, ..., u, c, alrea...\n",
      "4       [nah, i, do, n't, think, he, goes, to, usf, ,,...\n",
      "5       [freemsg, hey, there, darling, it, 's, been, 3...\n",
      "6       [even, my, brother, is, not, like, to, speak, ...\n",
      "7       [as, per, your, request, 'melle, melle, (, oru...\n",
      "8       [winner, !, !, as, a, valued, network, custome...\n",
      "9       [had, your, mobile, 11, months, or, more, ?, u...\n",
      "10      [i, 'm, gon, na, be, home, soon, and, i, do, n...\n",
      "11      [six, chances, to, win, cash, !, from, 100, to...\n",
      "12      [urgent, !, you, have, won, a, 1, week, free, ...\n",
      "13      [i, 've, been, searching, for, the, right, wor...\n",
      "14       [i, have, a, date, on, sunday, with, will, !, !]\n",
      "15      [xxxmobilemovieclub, :, to, use, your, credit,...\n",
      "16              [oh, k, ..., i, 'm, watching, here, :, )]\n",
      "17      [eh, u, remember, how, 2, spell, his, name, .....\n",
      "18      [fine, if, thats, the, way, u, feel, ., that...\n",
      "19      [england, v, macedonia, -, dont, miss, the, go...\n",
      "20      [is, that, seriously, how, you, spell, his, na...\n",
      "21      [i, ‘, m, going, to, try, for, 2, months, ha, ...\n",
      "22      [so, ü, pay, first, lar, ..., then, when, is, ...\n",
      "23      [aft, i, finish, my, lunch, then, i, go, str, ...\n",
      "24      [ffffffffff, ., alright, no, way, i, can, meet...\n",
      "25      [just, forced, myself, to, eat, a, slice, ., i...\n",
      "26                 [lol, your, always, so, convincing, .]\n",
      "27      [did, you, catch, the, bus, ?, are, you, fryin...\n",
      "28      [i, 'm, back, &, amp, ;, we, 're, packing, the...\n",
      "29      [ahhh, ., work, ., i, vaguely, remember, that,...\n",
      "                              ...                        \n",
      "5544    [armand, says, get, your, ass, over, to, epsilon]\n",
      "5545    [u, still, havent, got, urself, a, jacket, ah, ?]\n",
      "5546    [i, 'm, taking, derek, &, amp, ;, taylor, to, ...\n",
      "5547    [hi, its, in, durban, are, you, still, on, thi...\n",
      "5548    [ic, ., there, are, a, lotta, childporn, cars,...\n",
      "5549    [had, your, contract, mobile, 11, mnths, ?, la...\n",
      "5550      [no, ,, i, was, trying, it, all, weekend, ;, v]\n",
      "5551    [you, know, ,, wot, people, wear, ., t, shirts...\n",
      "5552    [cool, ,, what, time, you, think, you, can, ge...\n",
      "5553    [wen, did, you, get, so, spiritual, and, deep,...\n",
      "5554    [have, a, safe, trip, to, nigeria, ., wish, yo...\n",
      "5555                     [hahaha..use, your, brain, dear]\n",
      "5556    [well, keep, in, mind, i, 've, only, got, enou...\n",
      "5557    [yeh, ., indians, was, nice, ., tho, it, did, ...\n",
      "5558    [yes, i, have, ., so, that, 's, why, u, texted...\n",
      "5559    [no, ., i, meant, the, calculation, is, the, s...\n",
      "5560                      [sorry, ,, i, 'll, call, later]\n",
      "5561    [if, you, are, n't, here, in, the, next, &, lt...\n",
      "5562        [anything, lor, ., juz, both, of, us, lor, .]\n",
      "5563    [get, me, out, of, this, dump, heap, ., my, mo...\n",
      "5564    [ok, lor, ..., sony, ericsson, salesman, ..., ...\n",
      "5565                          [ard, 6, like, dat, lor, .]\n",
      "5566    [why, do, n't, you, wait, 'til, at, least, wed...\n",
      "5567                                   [huh, y, lei, ...]\n",
      "5568    [reminder, from, o2, :, to, get, 2.50, pounds,...\n",
      "5569    [this, is, the, 2nd, time, we, have, tried, 2,...\n",
      "5570      [will, ü, b, going, to, esplanade, fr, home, ?]\n",
      "5571    [pity, ,, *, was, in, mood, for, that, ., so, ...\n",
      "5572    [the, guy, did, some, bitching, but, i, acted,...\n",
      "5573                  [rofl, ., its, true, to, its, name]\n",
      "Name: token_word, Length: 5574, dtype: object [11]\n",
      "lemma_word:  0       [go, until, jurong, point, ,, crazy.., availab...\n",
      "1                [ok, lar, ..., joking, wif, u, oni, ...]\n",
      "2       [free, entry, in, 2, a, wkly, comp, to, win, f...\n",
      "3       [u, dun, say, so, early, hor, ..., u, c, alrea...\n",
      "4       [nah, i, do, n't, think, he, go, to, usf, ,, h...\n",
      "5       [freemsg, hey, there, darling, it, 's, been, 3...\n",
      "6       [even, my, brother, is, not, like, to, speak, ...\n",
      "7       [a, per, your, request, 'melle, melle, (, oru,...\n",
      "8       [winner, !, !, a, a, valued, network, customer...\n",
      "9       [had, your, mobile, 11, month, or, more, ?, u,...\n",
      "10      [i, 'm, gon, na, be, home, soon, and, i, do, n...\n",
      "11      [six, chance, to, win, cash, !, from, 100, to,...\n",
      "12      [urgent, !, you, have, won, a, 1, week, free, ...\n",
      "13      [i, 've, been, searching, for, the, right, wor...\n",
      "14       [i, have, a, date, on, sunday, with, will, !, !]\n",
      "15      [xxxmobilemovieclub, :, to, use, your, credit,...\n",
      "16              [oh, k, ..., i, 'm, watching, here, :, )]\n",
      "17      [eh, u, remember, how, 2, spell, his, name, .....\n",
      "18      [fine, if, thats, the, way, u, feel, ., that...\n",
      "19      [england, v, macedonia, -, dont, miss, the, go...\n",
      "20      [is, that, seriously, how, you, spell, his, na...\n",
      "21      [i, ‘, m, going, to, try, for, 2, month, ha, h...\n",
      "22      [so, ü, pay, first, lar, ..., then, when, is, ...\n",
      "23      [aft, i, finish, my, lunch, then, i, go, str, ...\n",
      "24      [ffffffffff, ., alright, no, way, i, can, meet...\n",
      "25      [just, forced, myself, to, eat, a, slice, ., i...\n",
      "26                 [lol, your, always, so, convincing, .]\n",
      "27      [did, you, catch, the, bus, ?, are, you, fryin...\n",
      "28      [i, 'm, back, &, amp, ;, we, 're, packing, the...\n",
      "29      [ahhh, ., work, ., i, vaguely, remember, that,...\n",
      "                              ...                        \n",
      "5544      [armand, say, get, your, as, over, to, epsilon]\n",
      "5545    [u, still, havent, got, urself, a, jacket, ah, ?]\n",
      "5546    [i, 'm, taking, derek, &, amp, ;, taylor, to, ...\n",
      "5547    [hi, it, in, durban, are, you, still, on, this...\n",
      "5548    [ic, ., there, are, a, lotta, childporn, car, ...\n",
      "5549    [had, your, contract, mobile, 11, mnths, ?, la...\n",
      "5550       [no, ,, i, wa, trying, it, all, weekend, ;, v]\n",
      "5551    [you, know, ,, wot, people, wear, ., t, shirt,...\n",
      "5552    [cool, ,, what, time, you, think, you, can, ge...\n",
      "5553    [wen, did, you, get, so, spiritual, and, deep,...\n",
      "5554    [have, a, safe, trip, to, nigeria, ., wish, yo...\n",
      "5555                     [hahaha..use, your, brain, dear]\n",
      "5556    [well, keep, in, mind, i, 've, only, got, enou...\n",
      "5557    [yeh, ., indian, wa, nice, ., tho, it, did, ka...\n",
      "5558    [yes, i, have, ., so, that, 's, why, u, texted...\n",
      "5559    [no, ., i, meant, the, calculation, is, the, s...\n",
      "5560                      [sorry, ,, i, 'll, call, later]\n",
      "5561    [if, you, are, n't, here, in, the, next, &, lt...\n",
      "5562         [anything, lor, ., juz, both, of, u, lor, .]\n",
      "5563    [get, me, out, of, this, dump, heap, ., my, mo...\n",
      "5564    [ok, lor, ..., sony, ericsson, salesman, ..., ...\n",
      "5565                          [ard, 6, like, dat, lor, .]\n",
      "5566    [why, do, n't, you, wait, 'til, at, least, wed...\n",
      "5567                                   [huh, y, lei, ...]\n",
      "5568    [reminder, from, o2, :, to, get, 2.50, pound, ...\n",
      "5569    [this, is, the, 2nd, time, we, have, tried, 2,...\n",
      "5570      [will, ü, b, going, to, esplanade, fr, home, ?]\n",
      "5571    [pity, ,, *, wa, in, mood, for, that, ., so, ....\n",
      "5572    [the, guy, did, some, bitching, but, i, acted,...\n",
      "5573                    [rofl, ., it, true, to, it, name]\n",
      "Name: lemma_word, Length: 5574, dtype: object [11]\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "def split_lemma(message):\n",
    "    lemma = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for word in message:\n",
    "        a=lemmatizer.lemmatize(word)\n",
    "        lemma.append(a)\n",
    "    return lemma\n",
    "\n",
    "dataset['lemma_word']=dataset.apply(lambda row:split_lemma(row['token_word']), axis=1)\n",
    "print(\"token_word: \", dataset['token_word'],[11])\n",
    "print(\"lemma_word: \", dataset['lemma_word'],[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def split_stop_words(message):\n",
    "    stop_words_split = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words_split = ' '.join([word for word in message if word not in stop_words])\n",
    "    return stop_words_split\n",
    "\n",
    "dataset[\"stop_words\"]=dataset.apply(lambda row:split_stop_words(row['lemma_word']), axis=1)\n",
    "\n",
    "Training_data = pd.Series(list(dataset[\"stop_words\"]))\n",
    "Training_label = pd.Series(list(dataset[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "tdm_vector = CountVectorizer(ngram_range=(1,2), min_df=(1/len(Training_label)), max_df=0.7)\n",
    "total_text = tdm_vector.fit(Training_data)\n",
    "tdm_total = total_text.transform(Training_data)\n",
    "\n",
    "tfidf_vector = TfidfVectorizer(ngram_range=(1,2), min_df=(1/len(Training_label)), max_df=0.7)\n",
    "tfidf_text = tfidf_vector.fit(Training_data)\n",
    "tfidf_total = tfidf_text.transform(Training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data, train_label, test_label = train_test_split(tfidf_total, Training_label, test_size=.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier :  0.982078853046595\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier=DecisionTreeClassifier()\n",
    "classifier = classifier.fit(train_data, train_label)\n",
    "message_predicted_target = classifier.predict(test_data)\n",
    "score = classifier.score(test_data, test_label)\n",
    "\n",
    "print('Decision Tree Classifier : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD score:  0.982078853046595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ggovinda\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "seed=7\n",
    "classifier = SGDClassifier(loss='modified_huber', shuffle=True, random_state=seed)\n",
    "classifier = classifier.fit(train_data, train_label)\n",
    "score_sgd = classifier.score(test_data, test_label)\n",
    "print(\"SGD score: \",score_sgd )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ggovinda\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC score :  0.8637992831541219\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "seed=7\n",
    "classifier = SVC(C=0.025, random_state=seed)\n",
    "classifier = classifier.fit(train_data, train_label)\n",
    "score_svc = classifier.score(test_data, test_label)\n",
    "print(\"SVC score : \", score_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier :  0.8637992831541219\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=10,random_state=seed)\n",
    "classifier = classifier.fit(train_data, train_label)\n",
    "score = classifier.score(test_data, test_label)\n",
    "\n",
    "print('Random Forest Classifier : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classification after model tuning 0.8637992831541219\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(max_depth=5, n_estimators=15, max_features=60,random_state=seed)\n",
    "\n",
    "classifier = classifier.fit(train_data, train_label)\n",
    "\n",
    "score=classifier.score(test_data, test_label)\n",
    "\n",
    "print('Random Forest classification after model tuning',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=7\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "#creating cross validation object with 10% test size \n",
    "cross_val = StratifiedShuffleSplit(Training_label,test_size=0.1,random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'StratifiedShuffleSplit' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-130-3c81b7256cfc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mscore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcross_val\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf_total\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train_index'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtfidf_total\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_index'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTraining_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train_index'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTraining_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_index'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'StratifiedShuffleSplit' object is not iterable"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    DecisionTreeClassifier(),\n",
    "    SGDClassifier(loss='modified_huber', shuffle=True),\n",
    "    SVC(C=0.025),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=10),\n",
    "   ]\n",
    "\n",
    "for clf in classifiers:\n",
    "    score=0\n",
    "    for train_index, test_index in cross_val:\n",
    "        X_train, X_test = tfidf_total['train_index'], tfidf_total['test_index']\n",
    "        y_train, y_test = Training_label['train_index'], Training_label['test_index']\n",
    "        clf.fit(X_train, y_train)\n",
    "        score=score+clf.score(X_test,y_test)\n",
    "    print (score)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.982078853046595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ham     482\n",
       "spam     76\n",
       "dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy Score',accuracy_score(test_label,message_predicted_target))  \n",
    "classifier = classifier.fit(train_data, train_label)\n",
    "clasifier = classifier.score(test_data, test_label)\n",
    "test_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix [[479   3]\n",
      " [  7  69]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('Confusion Matrix',confusion_matrix(test_label,message_predicted_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        spam       0.99      0.99      0.99       482\n",
      "         ham       0.96      0.91      0.93        76\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       558\n",
      "   macro avg       0.97      0.95      0.96       558\n",
      "weighted avg       0.98      0.98      0.98       558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = ['spam', 'ham']\n",
    "\n",
    "print(classification_report(test_label, message_predicted_target, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'spam']\n"
     ]
    }
   ],
   "source": [
    "print(dataset['label'].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
